{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer report",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNpwom5H9lAfpvwIWFIdLxO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICTKtD99rmN3",
        "colab_type": "text"
      },
      "source": [
        "# Data Collection for transfer analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgb105GKrxNJ",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "We will be using bs4 to parse through the html pages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF0yHyk9ygrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from urllib.request import Request, urlopen\n",
        "from random import randint,shuffle\n",
        "import time\n",
        "from time import sleep\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OscN1ilzlDLu",
        "colab_type": "code",
        "outputId": "2beb3841-1dac-4a72-8927-35c35aaaeb80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install user_agent\n",
        "import user_agent\n",
        "from user_agent import generate_user_agent, generate_navigator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: user_agent in /usr/local/lib/python3.6/dist-packages (0.1.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from user_agent) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAMpL2LxsDZz",
        "colab_type": "text"
      },
      "source": [
        "## Scraping News Websites for traffic news"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVpq5q0YsO2w",
        "colab_type": "text"
      },
      "source": [
        "### Skysports\n",
        "Skysports does not hold old transfer news (only 12 pages of it) on their website but they are lenient when it comes to scrappers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH5ee9Nqy3mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content = []\n",
        "skysports = [\n",
        "       \"https://www.skysports.com/football/transfer-news\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/2\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/3\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/4\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/5\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/6\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/7\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/8\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/9\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/10\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/11\",\n",
        "       \"https://www.skysports.com/football/transfer-news/more/12\"\n",
        "       ]\n",
        "for url in skysports:\n",
        "    page = urllib.request.urlopen(url)\n",
        "    soup = BeautifulSoup(page, 'html.parser')\n",
        "    regex = re.compile('news-item')\n",
        "    content_lis = soup.find_all('div', attrs={'class': regex})\n",
        "    for div in content_lis:\n",
        "        title = div.find('h2').getText()\n",
        "        link = div.find('a')[\"href\"]\n",
        "        x = re.search(\"^/transfer\" , link)\n",
        "        if x != None :\n",
        "          link = \"https://www.skysports.com\" + link;\n",
        "        topic = div.find('strong').getText().strip()\n",
        "        newspage = urllib.request.urlopen(link)\n",
        "        tsoup = BeautifulSoup(newspage, 'html.parser')\n",
        "        try:\n",
        "          article_title = tsoup.find('h1').getText()\n",
        "        except:\n",
        "          article_title = \"\"\n",
        "        try:\n",
        "          article_subtitle = tsoup.find('h2').getText()\n",
        "        except:\n",
        "          article_subtitle = \"\"\n",
        "        h3_array = tsoup.find_all('h3')\n",
        "        article_part = []\n",
        "        for h3 in h3_array : \n",
        "            article_part.append(h3.getText())\n",
        "        article_part = '\\n'.join(article_part)\n",
        "        p_array = tsoup.find_all('p')\n",
        "        article_content = []\n",
        "        for h3 in p_array : \n",
        "            article_content.append(h3.getText())\n",
        "        article_content = '\\n'.join(article_content)\n",
        "        regex = re.compile(\"highlight\")\n",
        "        try:\n",
        "          date = tsoup.find(\"span\" , attrs={\"class\":regex}).getText()\n",
        "        except:\n",
        "          date = \"\"\n",
        "        article = {\n",
        "            \"url\" : link ,\n",
        "            \"subscript\" : title ,\n",
        "            \"topic\" : topic ,\n",
        "            \"title\" : article_title ,\n",
        "            \"subtitle\" : article_subtitle ,\n",
        "            \"emphasis\" : article_part ,\n",
        "            \"content\" : article_content ,\n",
        "            \"date\" : date\n",
        "        }\n",
        "        content.append(article)\n",
        "df = pd.DataFrame(content)\n",
        "df.to_csv(\"skysport_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S89Smkn_sibj",
        "colab_type": "text"
      },
      "source": [
        "### Goal\n",
        "Goal.com has all its articles accessible but they have a strict robots.txt so we'll have to use a user agent to scrape data\n",
        "We'll also put a time delay as we are scraping a lot of information we do not want overload their servers with requests.\n",
        "\n",
        "* **Irresponsible web scraping can get you blocked from websites** \n",
        "* **Data scraped belongs to goal.com. Any form of redistribution will have legal consequences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA3_Dp_j6uNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headers = {'User-Agent': generate_user_agent()}\n",
        "content = []\n",
        "links = []\n",
        "goal = [\n",
        "        \"https://www.goal.com/en-us/transfer-news\"\n",
        "       ]\n",
        "for i in range(2,501):\n",
        "  new_url = goal[0]+\"/\"+str(i)\n",
        "  goal.append(new_url)\n",
        "shuffle(goal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwM6COoP7-qV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "n = 0\n",
        "program_starts = time.time()\n",
        "for url in goal:\n",
        "  print(url)\n",
        "  now = time.time()\n",
        "  print(\"{0} sites have been scraped .It has been {1} seconds\".format(n,now - program_starts))\n",
        "  sleep(randint(1,30))\n",
        "  request = Request(url, headers=headers)\n",
        "  page = urllib.request.urlopen(request)\n",
        "  soup = BeautifulSoup(page, 'html.parser')\n",
        "  content_lis = soup.find_all('article')\n",
        "  for article in content_lis :\n",
        "    regex = re.compile(\"article\")\n",
        "    link = article.find('a', attrs={'class': regex})\n",
        "    if link != None:\n",
        "      link = \"https://www.goal.com\"+link[\"href\"]  \n",
        "      links.append(link)\n",
        "  n = n + 1\n",
        "links = pd.DataFrame(links)\n",
        "links.to_csv(\"goal.csv\")  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlHH0CsqgGtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame()\n",
        "links = pd.read_csv(\"goal.csv\")\n",
        "links = list(links[\"0\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIUjjbElOr-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffle(links)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ivCRgVbO5LD",
        "colab_type": "code",
        "outputId": "216ae3f0-aa33-4564-934c-50b11d3fa7f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "headers = {'User-Agent': generate_user_agent()}\n",
        "n = 0\n",
        "program_starts = time.time()\n",
        "for url in tqdm(links):\n",
        "  try:\n",
        "    n = n+1\n",
        "    request = Request(url, headers=headers)\n",
        "    page = urllib.request.urlopen(request)\n",
        "    soup = BeautifulSoup(page, 'html.parser')\n",
        "    try:\n",
        "      article_title = soup.find(\"h1\").getText()\n",
        "    except:\n",
        "      article_title = \"\"\n",
        "    try:\n",
        "      regex = re.compile(\"teaser\")\n",
        "      article_subtitle = soup.find(\"div\",attrs={\"class\" : regex}).getText()\n",
        "    except:\n",
        "      article_subtitle = \"\"\n",
        "    h3_array = soup.find_all('h2')\n",
        "    article_part = []\n",
        "    for h3 in h3_array : \n",
        "        article_part.append(h3.getText())\n",
        "    article_part = '\\n'.join(article_part)\n",
        "    p_array = soup.find_all('p')\n",
        "    article_content = []\n",
        "    for h3 in p_array : \n",
        "        article_content.append(h3.getText())\n",
        "    article_content = '\\n'.join(article_content)\n",
        "    regex = re.compile(\"tags-list__link\")\n",
        "    taglist = soup.find_all(\"a\",attrs={\"class\" : regex})\n",
        "    tags = []\n",
        "    for tag in taglist:\n",
        "      tags.append(tag.getText())\n",
        "    topic = '+'.join(tags)\n",
        "    datetag = soup.find(\"time\")\n",
        "    date = datetag.getText()\n",
        "    article = {\n",
        "              \"url\" : url ,\n",
        "              \"subscript\" : article_title ,\n",
        "              \"topic\" : topic ,\n",
        "              \"title\" : article_title ,\n",
        "              \"subtitle\" : article_subtitle ,\n",
        "              \"emphasis\" : article_part ,\n",
        "              \"content\" : article_content ,\n",
        "              \"date\" : date.strip()\n",
        "          }\n",
        "    df = df.append(article , ignore_index=True)  \n",
        "    df.to_csv(\"transfer_data.csv\")\n",
        "  except:\n",
        "    n=n-1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 13013/13013 [5:48:17<00:00,  1.61s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdXZFGu1aX-1",
        "colab_type": "code",
        "outputId": "1cc921e6-503d-420d-cff9-25144125a8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12875, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LiFj8nDuXQj",
        "colab_type": "text"
      },
      "source": [
        "# Analysis of transfer reports\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ5Jx6PbYmhe",
        "colab_type": "text"
      },
      "source": [
        "## Training name entity recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvh9xwf-kK8T",
        "colab_type": "code",
        "outputId": "12186e3b-af49-4621-ed4f-460d06210c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg-fuNJwxS-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuwJkn-JkzUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/gdrive/My Drive/project stuff/transfer_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pPfmc_7lP7K",
        "colab_type": "code",
        "outputId": "20db06f0-44ff-4558-96d8-d9f83487f9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>date</th>\n",
              "      <th>emphasis</th>\n",
              "      <th>subscript</th>\n",
              "      <th>subtitle</th>\n",
              "      <th>title</th>\n",
              "      <th>topic</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Other English editions\\nKane suffered a seriou...</td>\n",
              "      <td>1/9/20</td>\n",
              "      <td>Trending News</td>\n",
              "      <td>Dembele on Tottenham's radar following Kane su...</td>\n",
              "      <td>News that the England striker will miss at le...</td>\n",
              "      <td>Dembele on Tottenham's radar following Kane su...</td>\n",
              "      <td>Transfers + Tottenham Hotspur + Olympique Lyo...</td>\n",
              "      <td>https://www.goal.com/en-us/news/dembele-on-tot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Other English editions\\nCristian Tello will le...</td>\n",
              "      <td>15:14   6/30/17</td>\n",
              "      <td>Trending News</td>\n",
              "      <td>Tello to join Real Betis from Barcelona in €5m...</td>\n",
              "      <td>After re-signing Gerard Deulofeu, the Catalan...</td>\n",
              "      <td>Tello to join Real Betis from Barcelona in €5m...</td>\n",
              "      <td>Transfers + Primera División + Tello + Real B...</td>\n",
              "      <td>https://www.goal.com/en-us/news/cristian-tello...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Other English editions\\nPep Guardiola accepts ...</td>\n",
              "      <td>17:56   1/22/19</td>\n",
              "      <td>Trending News</td>\n",
              "      <td>'I don't want sad players here' - Guardiola ad...</td>\n",
              "      <td>Nicolas Otamendi has drifted out of favour at...</td>\n",
              "      <td>'I don't want sad players here' - Guardiola ad...</td>\n",
              "      <td>Transfers + Manchester City + Nicolás Otamend...</td>\n",
              "      <td>https://www.goal.com/en-us/news/i-dont-want-sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Other English editions\\nPaul Clement has warne...</td>\n",
              "      <td>06:21   5/19/17</td>\n",
              "      <td>Trending News</td>\n",
              "      <td>Sigurdsson should remember Tottenham disappoin...</td>\n",
              "      <td>The Iceland international was unable to secur...</td>\n",
              "      <td>Sigurdsson should remember Tottenham disappoin...</td>\n",
              "      <td>Transfers + Swansea City + Tottenham Hotspur ...</td>\n",
              "      <td>https://www.goal.com/en-us/news/premier-league...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Other English editions\\nNeymar’s father has re...</td>\n",
              "      <td>06:32   7/2/19</td>\n",
              "      <td>Trending News</td>\n",
              "      <td>Neymar's father offers update on transfer plan...</td>\n",
              "      <td>Reports suggesting that discussions with Camp...</td>\n",
              "      <td>Neymar's father offers update on transfer plan...</td>\n",
              "      <td>Transfers + Barcelona + Neymar + Primera Divi...</td>\n",
              "      <td>https://www.goal.com/en-us/news/neymars-father...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12870</th>\n",
              "      <td>Other English editions\\nAntoine Griezmann unde...</td>\n",
              "      <td>12:03   6/19/18</td>\n",
              "      <td>Trending News\\nRelated</td>\n",
              "      <td>Griezmann understands Atletico fans' nerves ov...</td>\n",
              "      <td>After Barcelona were linked with signing the ...</td>\n",
              "      <td>Griezmann understands Atletico fans' nerves ov...</td>\n",
              "      <td>Transfers + Atlético Madrid + Atlético Madrid...</td>\n",
              "      <td>https://www.goal.com/en-us/news/griezmann-unde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12871</th>\n",
              "      <td>Other English editions\\nVictor Lindelof has sp...</td>\n",
              "      <td>4/4/17</td>\n",
              "      <td>Trending News</td>\n",
              "      <td>Lindelof breaks silence over Man Utd links</td>\n",
              "      <td>The defender has long been linked with a move...</td>\n",
              "      <td>Lindelof breaks silence over Man Utd links</td>\n",
              "      <td>Benfica + Manchester United + Premier League ...</td>\n",
              "      <td>https://www.goal.com/en-us/news/lindelof-break...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12872</th>\n",
              "      <td>Other English editions\\nSydney FC are believed...</td>\n",
              "      <td>12/5/17</td>\n",
              "      <td>Trending News\\nRelated</td>\n",
              "      <td>The Covert Agent: Sydney FC interested in snar...</td>\n",
              "      <td>EXCLUSIVE: Goal's resident spy reveals Graham...</td>\n",
              "      <td>The Covert Agent: Sydney FC interested in snar...</td>\n",
              "      <td>Transfers + A-League + Sydney + Nick Fitzgera...</td>\n",
              "      <td>https://www.goal.com/en-us/news/the-covert-age...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12873</th>\n",
              "      <td>Other English editions\\nLuka Jovic said his dr...</td>\n",
              "      <td>00:09   6/6/19</td>\n",
              "      <td>Trending News</td>\n",
              "      <td>'My dream comes true now' - Madrid recruit Jov...</td>\n",
              "      <td>The forward said his goodbyes to the German s...</td>\n",
              "      <td>'My dream comes true now' - Madrid recruit Jov...</td>\n",
              "      <td>Transfers + Real Madrid + Luka Jović + Primer...</td>\n",
              "      <td>https://www.goal.com/en-us/news/my-dream-comes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12874</th>\n",
              "      <td>Other English editions\\nBarcelona have moved t...</td>\n",
              "      <td>8/28/17</td>\n",
              "      <td>Trending News\\nRelated</td>\n",
              "      <td>Barcelona move to rule out Messi and Iniesta e...</td>\n",
              "      <td>The La Liga giants have sought to end any sug...</td>\n",
              "      <td>Barcelona move to rule out Messi and Iniesta e...</td>\n",
              "      <td>Transfers + Barcelona + Primera División + Li...</td>\n",
              "      <td>https://www.goal.com/en-us/news/barcelona-move...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12875 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 content  ...                                                url\n",
              "0      Other English editions\\nKane suffered a seriou...  ...  https://www.goal.com/en-us/news/dembele-on-tot...\n",
              "1      Other English editions\\nCristian Tello will le...  ...  https://www.goal.com/en-us/news/cristian-tello...\n",
              "2      Other English editions\\nPep Guardiola accepts ...  ...  https://www.goal.com/en-us/news/i-dont-want-sa...\n",
              "3      Other English editions\\nPaul Clement has warne...  ...  https://www.goal.com/en-us/news/premier-league...\n",
              "4      Other English editions\\nNeymar’s father has re...  ...  https://www.goal.com/en-us/news/neymars-father...\n",
              "...                                                  ...  ...                                                ...\n",
              "12870  Other English editions\\nAntoine Griezmann unde...  ...  https://www.goal.com/en-us/news/griezmann-unde...\n",
              "12871  Other English editions\\nVictor Lindelof has sp...  ...  https://www.goal.com/en-us/news/lindelof-break...\n",
              "12872  Other English editions\\nSydney FC are believed...  ...  https://www.goal.com/en-us/news/the-covert-age...\n",
              "12873  Other English editions\\nLuka Jovic said his dr...  ...  https://www.goal.com/en-us/news/my-dream-comes...\n",
              "12874  Other English editions\\nBarcelona have moved t...  ...  https://www.goal.com/en-us/news/barcelona-move...\n",
              "\n",
              "[12875 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk3_1fSRxYl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLSF86R5xh_2",
        "colab_type": "code",
        "outputId": "077f1bea-b972-4d58-9a90-04d4eb41e811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp36-none-any.whl size=98051305 sha256=21f948835a45ab2fb545dc18defd240a5700c96ec4c3af7964ccad5879528bb1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fxe5nrvn/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxQbVagG5Gj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import en_core_web_md"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_3Cn1uPxo60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = en_core_web_md.load()\n",
        "doc = nlp(u\"Kylian Mbappe to force a move from Paris Saint Germain to join Real Madrid in 2021\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9f18cIhx5c1",
        "colab_type": "code",
        "outputId": "286ec78e-fcb0-4d08-a5eb-8be6b5de81c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "for token in doc.ents :\n",
        "  print(token.text,spacy.explain(token.label_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kylian Mbappe People, including fictional\n",
            "Paris Saint Germain Buildings, airports, highways, bridges, etc.\n",
            "Real Madrid Companies, agencies, institutions, etc.\n",
            "2021 Absolute or relative dates or periods\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td7bNgXAY__S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "from urllib.request import Request, urlopen\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrpE0MCPZEXz",
        "colab_type": "code",
        "outputId": "6052d7b0-4e84-4cb9-f898-14bcc6f7d7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "!pip install user_agent\n",
        "import user_agent\n",
        "from user_agent import generate_user_agent, generate_navigator"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting user_agent\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/ca/15546284f62edfec7666ecb6403a6e77f5db850def37cd36f140d99cce02/user_agent-0.1.9.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from user_agent) (1.12.0)\n",
            "Building wheels for collected packages: user-agent\n",
            "  Building wheel for user-agent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for user-agent: filename=user_agent-0.1.9-cp36-none-any.whl size=18807 sha256=67974b92a392175b8ace7efc6c545a64c0490f3ac7c0d01bc249afb931c18465\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/80/3f/5d79277825042f2d4d447f594e3fc046f1e506f2b481d364b2\n",
            "Successfully built user-agent\n",
            "Installing collected packages: user-agent\n",
            "Successfully installed user-agent-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LruUemNpZUr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headers = {'User-Agent': generate_user_agent()}\n",
        "url = \"https://www.uefa.com/memberassociations/leaguesandcups/index.html\" \n",
        "request = Request(url, headers=headers)\n",
        "page = urllib.request.urlopen(request)\n",
        "soup = BeautifulSoup(page, 'html.parser')\n",
        "regex = re.compile('^\\d+')\n",
        "countries = [(x.text,\"https://www.uefa.com/\"+x.find(\"a\")[\"href\"]) for x in soup.find_all('li', attrs={'class': regex})]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_AcwN4-a5rI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teams = []\n",
        "for country,url in countries:\n",
        "  request = Request(url, headers=headers)\n",
        "  page = urllib.request.urlopen(request)\n",
        "  soup = BeautifulSoup(page, 'html.parser')\n",
        "  regex = re.compile('^club')\n",
        "  teams = teams + [(team.text , \"https://www.uefa.com/\"+team.find(\"a\")[\"href\"],country) for team in soup.find_all(\"td\" , attrs={\"class\",regex})]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD2kSijieqdU",
        "colab_type": "code",
        "outputId": "340ee7e5-b06a-4a2b-bfd5-e70e189dc22c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "players = []\n",
        "for team in tqdm(teams):\n",
        "  url = team[1]\n",
        "  request = Request(url, headers=headers)\n",
        "  page = urllib.request.urlopen(request)\n",
        "  soup = BeautifulSoup(page, 'html.parser')\n",
        "  regex = re.compile('^playername')\n",
        "  players = players + [(x.text,team[0]) for x in soup.find_all(\"td\",attrs={\"class\":regex})]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 721/721 [09:34<00:00,  1.25it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMAtkvdXP3Yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-nAuVsvdgO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import shuffle\n",
        "shuffle(teams) \n",
        "shuffle(players)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w1gqixMeniZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_DATA = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1ZyxeSaXoOV",
        "colab_type": "text"
      },
      "source": [
        "### Training the named entity recognizer of a en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApBJnM2HXV4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL1 = \"TEAM\"\n",
        "LABEL2 = \"PLAYER\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxbeRnEFeqqJ",
        "colab_type": "code",
        "outputId": "2f9820b4-0411-4956-ac2a-08e4adf682c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "for team in teams[:200]:\n",
        "  sentence = team[0]+\" is a club from \"+team[2]+\".\"\n",
        "  ent = {\"entities\" : [(0,len(team[0]),LABEL1),(len(team[0])+16,len(sentence)-1,\"GPE\")]}\n",
        "  TRAINING_DATA = TRAINING_DATA + [(sentence , ent)]\n",
        "print(TRAINING_DATA[-1])\n",
        "\n",
        "for team in teams[200:400]:\n",
        "  sentence = team[0]+\" plays in \"+team[2]+\".\"\n",
        "  ent = {\"entities\" : [(0,len(team[0]),LABEL1),(len(team[0])+10,len(sentence)-1,\"GPE\")]}\n",
        "  TRAINING_DATA = TRAINING_DATA + [(sentence , ent)]\n",
        "print(TRAINING_DATA[-1])\n",
        "\n",
        "for team in teams[400:550]:\n",
        "  sentence = team[0]+\" is a successful club.\"\n",
        "  ent = {\"entities\" : [(0,len(team[0]),LABEL1)]}\n",
        "  TRAINING_DATA = TRAINING_DATA + [(sentence , ent)]\n",
        "print(TRAINING_DATA[-1])\n",
        "\n",
        "for team in teams[550:]:\n",
        "  sentence = \"The \"+team[2]+\" based club \"+team[0]+\".\"\n",
        "  ent = {\"entities\" : [(4,len(team[2]),\"GPE\"),(16+len(team[2]),16+len(team[2])+len(team[0]),LABEL1)]}\n",
        "  TRAINING_DATA = TRAINING_DATA + [(sentence , ent)]\n",
        "print(TRAINING_DATA[-1])\n",
        "\n",
        "for player in players[0:100]:\n",
        "  sentence = player[0]+\" wants to join \"+player[1]\n",
        "  ent = {\n",
        "      \"entities\" : [\n",
        "                    (0 , len(player[0]) ,LABEL2 ) ,\n",
        "                    (15 + len(player[0]), 15 + len(player[0]) + len(player[1]) , LABEL1)\n",
        "                    ]\n",
        "      }\n",
        "  TRAINING_DATA = TRAINING_DATA + [(sentence , ent)]\n",
        "print(TRAINING_DATA[-1])\n",
        "\n",
        "for player in players[100:200]:\n",
        "  sentence = player[0]+\" is looking to leave \"+player[1]\n",
        "  ent = {\n",
        "      \"entities\" : [\n",
        "                    (0 , len(player[0]) ,LABEL2 ) ,\n",
        "                    (21 + len(player[0]), 21 + len(player[0]) + len(player[1]) , LABEL1)\n",
        "                    ]\n",
        "      }\n",
        "  TRAINING_DATA = TRAINING_DATA + [(sentence , ent)]\n",
        "print(TRAINING_DATA[-1])\n",
        "\n",
        "for player in players[200:300]:\n",
        "  sentence = player[0]+\" is happy at \"+player[1]\n",
        "  ent = {\n",
        "      \"entities\" : [\n",
        "                    (0 , len(player[0]) ,LABEL2 ) ,\n",
        "                    (13 + len(player[0]), 13 + len(player[0]) + len(player[1]) , LABEL1)\n",
        "                    ]\n",
        "      }\n",
        "  TRAINING_DATA = TRAINING_DATA + [(sentence , ent)]\n",
        "print(TRAINING_DATA[-1])\n",
        "\n",
        "for player in players[300:400]:\n",
        "  sentence = player[1]+\" wants to sign \"+player[0]\n",
        "  ent = {\n",
        "      \"entities\" : [\n",
        "                    (0 , len(player[1]) ,LABEL1 ) ,\n",
        "                    (15 + len(player[1]), 15 + len(player[0]) + len(player[1]) , LABEL2)\n",
        "                    ]\n",
        "      }\n",
        "  TRAINING_DATA = TRAINING_DATA + [(sentence , ent)]\n",
        "print(TRAINING_DATA[-1])\n",
        "\n",
        "for player in players[400:500]:\n",
        "  sentence = player[1]+\" makes offer for \"+player[0]\n",
        "  ent = {\n",
        "      \"entities\" : [\n",
        "                    (0 , len(player[1]) ,LABEL1 ) ,\n",
        "                    (16 + len(player[1]), 16 + len(player[0]) + len(player[1]) , LABEL2)\n",
        "                    ]\n",
        "      }\n",
        "  TRAINING_DATA = TRAINING_DATA + [(sentence , ent)]\n",
        "print(TRAINING_DATA[-1])\n",
        "\n",
        "for player in players[500:600]:\n",
        "  sentence = player[1]+\" trying to kick out \"+player[0]\n",
        "  ent = {\n",
        "      \"entities\" : [\n",
        "                    (0 , len(player[1]) ,LABEL1 ) ,\n",
        "                    (20 + len(player[1]), 20 + len(player[0]) + len(player[1]) , LABEL2)\n",
        "                    ]\n",
        "      }\n",
        "  TRAINING_DATA = TRAINING_DATA + [(sentence , ent)]\n",
        "print(TRAINING_DATA[-1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('RB Leipzig is a club from Germany.', {'entities': [(0, 10, 'TEAM'), (26, 33, 'GPE')]})\n",
            "('Coleraine FC plays in Northern Ireland.', {'entities': [(0, 12, 'TEAM'), (22, 38, 'GPE')]})\n",
            "('FC Etzella Ettelbruck is a successful club.', {'entities': [(0, 21, 'TEAM')]})\n",
            "('The Slovakia based club SK Sered.', {'entities': [(4, 8, 'GPE'), (24, 32, 'TEAM')]})\n",
            "('Anderson Esiti wants to join PAOK FC', {'entities': [(0, 14, 'PLAYER'), (29, 36, 'TEAM')]})\n",
            "('Max Grün is looking to leave VfL Borussia Mönchengladbach', {'entities': [(0, 8, 'PLAYER'), (29, 57, 'TEAM')]})\n",
            "('Danijel Subašić is happy at AS Monaco FC', {'entities': [(0, 15, 'PLAYER'), (28, 40, 'TEAM')]})\n",
            "('Eintracht Frankfurt wants to sign Almamy Touré', {'entities': [(0, 19, 'TEAM'), (34, 46, 'PLAYER')]})\n",
            "('SL Benfica makes offer for Pizzi', {'entities': [(0, 10, 'TEAM'), (26, 31, 'PLAYER')]})\n",
            "('Juventus trying to kick out Mattia De Sciglio', {'entities': [(0, 8, 'TEAM'), (28, 45, 'PLAYER')]})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr-Q7SBIs64c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ner = nlp.get_pipe(\"ner\")\n",
        "ner.add_label(LABEL1)\n",
        "ner.add_label(LABEL2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhKKJCYqtltI",
        "colab_type": "code",
        "outputId": "de785453-1b2e-4d06-dcd8-ee8ad8dbbf84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "move_names = list(ner.move_names)\n",
        "print(move_names)\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "other_pipes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-ORG', 'B-DATE', 'B-PERSON', 'B-GPE', 'B-MONEY', 'B-CARDINAL', 'B-NORP', 'B-PERCENT', 'B-WORK_OF_ART', 'B-LOC', 'B-TIME', 'B-QUANTITY', 'B-FAC', 'B-EVENT', 'B-ORDINAL', 'B-PRODUCT', 'B-LAW', 'B-LANGUAGE', 'I-ORG', 'I-DATE', 'I-PERSON', 'I-GPE', 'I-MONEY', 'I-CARDINAL', 'I-NORP', 'I-PERCENT', 'I-WORK_OF_ART', 'I-LOC', 'I-TIME', 'I-QUANTITY', 'I-FAC', 'I-EVENT', 'I-ORDINAL', 'I-PRODUCT', 'I-LAW', 'I-LANGUAGE', 'L-ORG', 'L-DATE', 'L-PERSON', 'L-GPE', 'L-MONEY', 'L-CARDINAL', 'L-NORP', 'L-PERCENT', 'L-WORK_OF_ART', 'L-LOC', 'L-TIME', 'L-QUANTITY', 'L-FAC', 'L-EVENT', 'L-ORDINAL', 'L-PRODUCT', 'L-LAW', 'L-LANGUAGE', 'U-ORG', 'U-DATE', 'U-PERSON', 'U-GPE', 'U-MONEY', 'U-CARDINAL', 'U-NORP', 'U-PERCENT', 'U-WORK_OF_ART', 'U-LOC', 'U-TIME', 'U-QUANTITY', 'U-FAC', 'U-EVENT', 'U-ORDINAL', 'U-PRODUCT', 'U-LAW', 'U-LANGUAGE', 'O', 'B-TEAM', 'I-TEAM', 'L-TEAM', 'U-TEAM', 'B-PLAYER', 'I-PLAYER', 'L-PLAYER', 'U-PLAYER']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tagger', 'parser']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb7Lf06v7Aw8",
        "colab_type": "code",
        "outputId": "bf414369-ff31-49a3-8b96-b00dc438c766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from spacy.util import compounding , minibatch\n",
        "n_iter = 10\n",
        "optimizer = nlp.resume_training()\n",
        "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "  sizes = compounding(1.0, 4.0, 1.001)\n",
        "  for itn in tqdm(range(n_iter)):\n",
        "      shuffle(TRAINING_DATA)\n",
        "      batches = minibatch(TRAINING_DATA, size=sizes)\n",
        "      losses = {}\n",
        "      for batch in batches:\n",
        "          texts, annotations = zip(*batch)\n",
        "          nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
        "      print(\"Losses\", losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [00:35<05:18, 35.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 6640.267859108897}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:54<04:03, 30.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 5714.571954773051}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [01:09<03:00, 25.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 5600.872271161716}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [01:25<02:16, 22.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 5507.713660135628}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [01:42<01:45, 21.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 5305.685669280916}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [02:00<01:20, 20.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 5370.524576131687}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [02:17<00:57, 19.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 5271.918183740383}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [02:34<00:37, 18.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 5362.253509901296}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [02:51<00:18, 18.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 5168.127331932454}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [03:09<00:00, 18.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 5315.679766376521}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti3MvdgTO1AU",
        "colab_type": "code",
        "outputId": "eb7c1400-05bc-41a4-e5ac-1e5d4b494c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install pathlib\n",
        "from pathlib import Path\n",
        "new_model_name = \"en_fnew_md\"\n",
        "output_dir = \"./en_fnew_md\"\n",
        "output_dir = Path(output_dir)\n",
        "if not output_dir.exists():\n",
        "    output_dir.mkdir()\n",
        "nlp.meta[\"name\"] = new_model_name  # rename model\n",
        "nlp.to_disk(output_dir)\n",
        "print(\"Saved model to\", output_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Saved model to en_fnew_md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXYQnwAtXy8u",
        "colab_type": "text"
      },
      "source": [
        "### Completely Training a large language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PKi9zM7XhBF",
        "colab_type": "text"
      },
      "source": [
        "We will be training the dependency parser as well as the named entity recognizer again\n",
        "This time while training the NER we will try making a more natural Training dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxcoq0nBYV66",
        "colab_type": "text"
      },
      "source": [
        "#### Training the NER (2nd approach)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad9mD3katChr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL1 = \"TEAM\"\n",
        "LABEL2 = \"PLAYER\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGBQ3nZ7W5HI",
        "colab_type": "code",
        "outputId": "cd8e8ef1-cd5f-4ddd-c059-87e25e27d053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "players[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Jan Koprivec', 'Kilmarnock FC')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cns6Me4FW5Z6",
        "colab_type": "code",
        "outputId": "a4a3babe-2354-49c7-86a5-ea3d3598e4df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "teams[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Southampton FC',\n",
              " 'https://www.uefa.com//teamsandplayers/teams/club=52923/domestic/index.html',\n",
              " 'England')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP5IXSAgaOwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "templates = [{\"sent\" : x , \"tags\" : y} for x,y in zip( df[\"title\"][0:100] , df[\"topic\"][0:100] )]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "715ChkaQaHMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for tem in templates:\n",
        "  tags = [x.strip() for x in tem[\"tags\"].split(\"+\")]\n",
        "  doc = nlp(tem[\"sent\"])\n",
        "  tem[\"gaps\"] = []\n",
        "  tem[\"label\"] = []\n",
        "  print(tem[\"sent\"])\n",
        "  print(tags)\n",
        "  for token in doc.ents:\n",
        "    prev = 0\n",
        "    if token.text in tags:\n",
        "      print(token.text , token.label_)\n",
        "    elif token.label_ in [\"PERSON\",\"ORG\",\"GPE\"]:\n",
        "      print(token.text , token.label_)\n",
        "    ltype = input()\n",
        "    if ltype == 'p':\n",
        "      regex = re.compile(token.text)\n",
        "      loc = re.search(regex , tem[\"sent\"]).span()\n",
        "      tem[\"label\"].append(LABEL2)\n",
        "      prev = loc[1]\n",
        "      tem[\"sent\"] = tem[\"sent\"].replace(token.text , \"<PLAYER>\" , 1)\n",
        "    elif ltype == 'o':\n",
        "      regex = re.compile(token.text)\n",
        "      loc = re.search(regex , tem[\"sent\"]).span()\n",
        "      tem[\"label\"].append(LABEL1)\n",
        "      prev = loc[1]\n",
        "      tem[\"sent\"] = tem[\"sent\"].replace(token.text , \"<TEAM>\" , 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tMaL6FG7EIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "templates = pd.DataFrame(templates)\n",
        "templates.to_csv(\"/content/gdrive/My Drive/project stuff/training_template.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc7FV-95EBO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "templates = pd.read_csv(\"/content/gdrive/My Drive/project stuff/training_template.csv\")\n",
        "template = list(templates[\"sent\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRVxfm8k9rzt",
        "colab_type": "code",
        "outputId": "5fb0a3fd-06d9-48f9-f655-0126c68d16e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from random import randint\n",
        "def getTrainingSample():\n",
        "  sent = template[randint(0,len(template)-1)]\n",
        "  ent = {\"entities\" : [] }\n",
        "  key = re.search(r\"<\\w+>\" , sent)\n",
        "  while key != None :\n",
        "    if key.group() == \"<PLAYER>\":\n",
        "      player = players[randint(0,len(players)-1)][0]\n",
        "      sent = sent.replace(\"<PLAYER>\" , player , 1)\n",
        "      ent[\"entities\"].append((key.span()[0] , key.span()[0] + len(player) , LABEL2))\n",
        "    elif key.group() == \"<TEAM>\":\n",
        "      team = teams[randint(0,len(teams)-1)][0]\n",
        "      sent = sent.replace(\"<TEAM>\" , team , 1)\n",
        "      ent[\"entities\"].append((key.span()[0] , key.span()[0] + len(team) , LABEL1))\n",
        "    key = re.search(r\"<\\w+>\" , sent)\n",
        "  return (sent , ent)\n",
        "print(getTrainingSample())\n",
        "shuffle(TRAINING_DATA)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(\"'Is Azz-Eddine Ounahi leaving? Is he ill?' - Wright demands FC Girondins de Bordeaux clarify German's future\", {'entities': [(4, 21, 'PLAYER'), (60, 84, 'TEAM')]})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHOcaIAmEtRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,1000):\n",
        "  TRAINING_DATA.append(getTrainingSample())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z93WrWlpFSfZ",
        "colab_type": "code",
        "outputId": "1486bc21-a4cc-4e6c-f0dc-a4653c10d2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"brown\")\n",
        "from nltk.corpus import brown\n",
        "for x in brown.fileids()[:5]:\n",
        "  for y in brown.sents(x):\n",
        "    TRAINING_DATA.append((\n",
        "        \" \".join(y).replace(\"`\",\"\").replace(\"'\",\"\") ,\n",
        "        {\"entities\" : []}\n",
        "    ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu4Z_FkfGKt5",
        "colab_type": "code",
        "outputId": "a05da586-f0c6-4a5a-840a-466cf1f8a68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(TRAINING_DATA)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2801"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EByRk5zQZBva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = en_core_web_md.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YhuHCXgnV_h",
        "colab_type": "code",
        "outputId": "81a9a268-a5e3-4f37-a35f-790750a19631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(df[\"title\"])[9983]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"'Leave Real Madrid? I have the same desire to die!' - Navas bullish despite Courtois arrival\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoOOo0VLVfzT",
        "colab_type": "code",
        "outputId": "4e39ad54-df10-4027-aa3e-7833cd435ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "from random import randint , shuffle\n",
        "def test_model():\n",
        "  print(\"\\nTESTING MODEL\\n\")\n",
        "  for i in range(0,5):\n",
        "    text = list(df[\"title\"])[randint(0,10000)]\n",
        "    doc = nlp(text)\n",
        "    print(\"\\t\"+text)\n",
        "    print(\"\\t\\tEntities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "    print(\"\")\n",
        "test_model()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TESTING MODEL\n",
            "\n",
            "\t'If I can bring Kylian to Real Madrid I will try' - Hazard would relish link-up with Mbappe\n",
            "\t\tEntities [('Kylian', 'PERSON')]\n",
            "\n",
            "\tCardona confirms Monterrey exit as he dreams of playing for Boca\n",
            "\t\tEntities [('Cardona', 'PERSON'), ('Monterrey', 'GPE'), ('Boca', 'FAC')]\n",
            "\n",
            "\tLille president 'confirms' Pepe to Arsenal for €80m\n",
            "\t\tEntities [('Lille', 'GPE'), ('Pepe', 'PERSON'), ('€80m', 'MONEY')]\n",
            "\n",
            "\tSarri requests Chelsea exit as agreement reached with Juventus\n",
            "\t\tEntities [('Sarri', 'PERSON'), ('Chelsea', 'PERSON'), ('Juventus', 'ORG')]\n",
            "\n",
            "\tInter Miami have held Cavani talks as Beckham’s new MLS franchise seek marquee signing\n",
            "\t\tEntities [('Inter Miami', 'ORG'), ('Cavani', 'PERSON'), ('Beckham', 'PERSON'), ('MLS', 'ORG')]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp9XC_5vVhN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ner = nlp.get_pipe(\"ner\")\n",
        "ner.add_label(LABEL1)\n",
        "ner.add_label(LABEL2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11suYkM7XPT5",
        "colab_type": "code",
        "outputId": "02320f6a-580a-454e-8801-1c1522d828e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "move_names = list(ner.move_names)\n",
        "print(move_names)\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "other_pipes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-ORG', 'B-DATE', 'B-PERSON', 'B-GPE', 'B-MONEY', 'B-CARDINAL', 'B-NORP', 'B-PERCENT', 'B-WORK_OF_ART', 'B-LOC', 'B-TIME', 'B-QUANTITY', 'B-FAC', 'B-EVENT', 'B-ORDINAL', 'B-PRODUCT', 'B-LAW', 'B-LANGUAGE', 'I-ORG', 'I-DATE', 'I-PERSON', 'I-GPE', 'I-MONEY', 'I-CARDINAL', 'I-NORP', 'I-PERCENT', 'I-WORK_OF_ART', 'I-LOC', 'I-TIME', 'I-QUANTITY', 'I-FAC', 'I-EVENT', 'I-ORDINAL', 'I-PRODUCT', 'I-LAW', 'I-LANGUAGE', 'L-ORG', 'L-DATE', 'L-PERSON', 'L-GPE', 'L-MONEY', 'L-CARDINAL', 'L-NORP', 'L-PERCENT', 'L-WORK_OF_ART', 'L-LOC', 'L-TIME', 'L-QUANTITY', 'L-FAC', 'L-EVENT', 'L-ORDINAL', 'L-PRODUCT', 'L-LAW', 'L-LANGUAGE', 'U-ORG', 'U-DATE', 'U-PERSON', 'U-GPE', 'U-MONEY', 'U-CARDINAL', 'U-NORP', 'U-PERCENT', 'U-WORK_OF_ART', 'U-LOC', 'U-TIME', 'U-QUANTITY', 'U-FAC', 'U-EVENT', 'U-ORDINAL', 'U-PRODUCT', 'U-LAW', 'U-LANGUAGE', 'O', 'B-TEAM', 'I-TEAM', 'L-TEAM', 'U-TEAM', 'B-PLAYER', 'I-PLAYER', 'L-PLAYER', 'U-PLAYER']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tagger', 'parser']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxj-6DXYXPfG",
        "colab_type": "code",
        "outputId": "0acd308b-4b10-47b9-a4ef-97e37af2e803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from spacy.util import compounding , minibatch\n",
        "n_iter = 30\n",
        "optimizer = nlp.resume_training()\n",
        "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "  sizes = compounding(1.0, 4.0, 1.001)\n",
        "  last_loss = 42327.484182610715 \n",
        "  for itn in tqdm(range(n_iter)):\n",
        "      shuffle(TRAINING_DATA)\n",
        "      batches = minibatch(TRAINING_DATA, size=sizes)\n",
        "      losses = {}\n",
        "      for batch in batches:\n",
        "          texts, annotations = zip(*batch)\n",
        "          nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
        "      clear_output(wait=True)\n",
        "      test_model()\n",
        "      print(\"Loss \", losses)\n",
        "      print(\"Rate \", (last_loss - losses[\"ner\"])/last_loss)\n",
        "      last_loss = losses[\"ner\"]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [18:06<00:00, 36.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TESTING MODEL\n",
            "\n",
            "\tGullit urges Chelsea to reject Madrid advances for Hazard\n",
            "\t\tEntities []\n",
            "\t\tTokens [('Gullit', '', 2), ('urges', '', 2), ('Chelsea', '', 2), ('to', '', 2), ('reject', '', 2), ('Madrid', '', 2), ('advances', '', 2), ('for', '', 2), ('Hazard', '', 2)]\n",
            "\n",
            "\tJuventus to sign Bernardeschi for €40m\n",
            "\t\tEntities [('Juventus', 'TEAM'), ('Bernardeschi', 'PLAYER')]\n",
            "\t\tTokens [('Juventus', 'TEAM', 3), ('to', '', 2), ('sign', '', 2), ('Bernardeschi', 'PLAYER', 3), ('for', '', 2), ('€', '', 2), ('40', '', 2), ('m', '', 2)]\n",
            "\n",
            "\tHazard drops hint that he'd consider Chelsea exit\n",
            "\t\tEntities []\n",
            "\t\tTokens [('Hazard', '', 2), ('drops', '', 2), ('hint', '', 2), ('that', '', 2), ('he', '', 2), (\"'d\", '', 2), ('consider', '', 2), ('Chelsea', '', 2), ('exit', '', 2)]\n",
            "\n",
            "\tGood for Bayern that Aubameyang is not leaving Dortmund – Lewandowski\n",
            "\t\tEntities []\n",
            "\t\tTokens [('Good', '', 2), ('for', '', 2), ('Bayern', '', 2), ('that', '', 2), ('Aubameyang', '', 2), ('is', '', 2), ('not', '', 2), ('leaving', '', 2), ('Dortmund', '', 2), ('–', '', 2), ('Lewandowski', '', 2)]\n",
            "\n",
            "\tLindelof has done 'absolutely nothing' in football! - Ex-Man Utd midfielder\n",
            "\t\tEntities [('Lindelof', 'TEAM')]\n",
            "\t\tTokens [('Lindelof', 'TEAM', 3), ('has', '', 2), ('done', '', 2), (\"'\", '', 2), ('absolutely', '', 2), ('nothing', '', 2), (\"'\", '', 2), ('in', '', 2), ('football', '', 2), ('!', '', 2), ('-', '', 2), ('Ex', '', 2), ('-', '', 2), ('Man', '', 2), ('Utd', '', 2), ('midfielder', '', 2)]\n",
            "\n",
            "Loss  {'ner': 18646.264301878673}\n",
            "Rate  -0.010754382272748815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_BlMdLgXlSO",
        "colab_type": "code",
        "outputId": "ff0cff70-c29b-465f-af3d-511b64a44e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install pathlib\n",
        "from pathlib import Path\n",
        "new_model_name = \"en_fnew_md\"\n",
        "output_dir = \"./en_fnew_md\"\n",
        "output_dir = Path(output_dir)\n",
        "if not output_dir.exists():\n",
        "    output_dir.mkdir()\n",
        "nlp.meta[\"name\"] = new_model_name  # rename model\n",
        "nlp.to_disk(output_dir)\n",
        "print(\"Saved model to\", output_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Saved model to en_fnew_md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z72p-QLsYTrl",
        "colab_type": "code",
        "outputId": "6db61a6b-c922-4812-9eb4-6d6474fe0b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "!zip -r /content/gdrive/My\\ Drive/project\\ stuff/fmodel.zip en_fnew_md"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: en_fnew_md/ (stored 0%)\n",
            "updating: en_fnew_md/parser/ (stored 0%)\n",
            "updating: en_fnew_md/parser/model (deflated 7%)\n",
            "updating: en_fnew_md/parser/moves (deflated 56%)\n",
            "updating: en_fnew_md/parser/cfg (deflated 49%)\n",
            "updating: en_fnew_md/meta.json (deflated 46%)\n",
            "updating: en_fnew_md/tagger/ (stored 0%)\n",
            "updating: en_fnew_md/tagger/model (deflated 7%)\n",
            "updating: en_fnew_md/tagger/cfg (deflated 34%)\n",
            "updating: en_fnew_md/tagger/tag_map (deflated 50%)\n",
            "updating: en_fnew_md/ner/ (stored 0%)\n",
            "updating: en_fnew_md/ner/model (deflated 8%)\n",
            "updating: en_fnew_md/ner/moves (deflated 78%)\n",
            "updating: en_fnew_md/ner/cfg (deflated 49%)\n",
            "updating: en_fnew_md/tokenizer (deflated 79%)\n",
            "updating: en_fnew_md/vocab/ (stored 0%)\n",
            "updating: en_fnew_md/vocab/key2row (deflated 78%)\n",
            "updating: en_fnew_md/vocab/strings.json (deflated 61%)\n",
            "updating: en_fnew_md/vocab/lookups.bin (deflated 45%)\n",
            "updating: en_fnew_md/vocab/vectors (deflated 9%)\n",
            "updating: en_fnew_md/vocab/lexemes.bin (deflated 64%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9AUeNHhyIQ5",
        "colab_type": "text"
      },
      "source": [
        "#### Using Matcher and phrase matcher to improve training data quality "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCrdVRA10Cv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6042cbfc-83fe-42ac-a7f5-a8eb8a3ad186"
      },
      "source": [
        "import seaborn as sns\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5t2lUT4yM--",
        "colab_type": "code",
        "outputId": "5b5becd4-c011-48cf-b692-1c8c477153f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "players[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Catalin Constantin Barbu', 'Chindia Targoviste')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-sDPz-Wzt2K",
        "colab_type": "code",
        "outputId": "2e61c337-ae2b-4dc4-c586-c76b581f8ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "teams[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ŁKS Łódź',\n",
              " 'https://www.uefa.com//teamsandplayers/teams/club=53004/domestic/index.html',\n",
              " 'Poland')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvUfHoayz0Lc",
        "colab_type": "code",
        "outputId": "0da5648a-bf5b-4cba-aa62-ccfc93700c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[\"title\"][0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Dembele on Tottenham's radar following Kane surgery blow\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUtOoy84z-a8",
        "colab_type": "code",
        "outputId": "7f530320-c9cb-454e-8f8d-b7b9379a7df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[\"topic\"][0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Transfers + Tottenham Hotspur + Olympique Lyonnais + Moussa Dembélé + Premier League + Harry Kane + Ligue 1 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmXynlkf1qqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrB6YD3CXQe7",
        "colab_type": "code",
        "outputId": "966aaad7-24b5-49ec-a4e2-b2648841d528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import unicodedata\n",
        "def strip_accents(text):\n",
        "    try:\n",
        "        text = unicode(text, 'utf-8')\n",
        "    except NameError: # unicode is a default on python 3 \n",
        "        pass\n",
        "    text = unicodedata.normalize('NFD', text)\\\n",
        "           .encode('ascii', 'ignore')\\\n",
        "           .decode(\"utf-8\")\n",
        "    return str(text)\n",
        "s = strip_accents('àéêöhello')\n",
        "print(s)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aeeohello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mdDAj3rYN83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "status = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJzB3gYgR5gf",
        "colab_type": "code",
        "outputId": "69cbe5f7-ecc9-4c3d-e9d8-1c7fcf31f096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "## enter possible extra team names\n",
        "txt = input()\n",
        "while txt != \"\":\n",
        "  status[txt] = \"TEAM\"\n",
        "  txt = input()  "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "liv\n",
            "reds\n",
            "psg\n",
            "bar\n",
            "fcb\n",
            "man city\n",
            "man utd\n",
            "utd\n",
            "rma\n",
            "blues\n",
            "whites\n",
            "seagulls\n",
            "wolves\n",
            "cules\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxZ5jnJs2Jnx",
        "colab_type": "code",
        "outputId": "357d615a-0cab-4faa-b5fa-66de14bed1c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "for title in tqdm(df[\"content\"]):\n",
        "  doc = nlp(title.lower())\n",
        "  for t in doc.ents:\n",
        "    if t.label_ in [\"ORG\" , \"GPE\" , \"PERSON\",\"FAC\"]:\n",
        "      match = re.search(r\"(([a-z]+.?)+)\",t.text)\n",
        "      if match != None:\n",
        "        t = strip_accents(match.group())\n",
        "        if t not in status: \n",
        "          for team in teams:  \n",
        "            if t in strip_accents(team[0].lower()):\n",
        "              status[t] = \"TEAM\"\n",
        "              break\n",
        "        if t not in status:\n",
        "          for player in players:\n",
        "            if t in strip_accents(player[0].lower()):\n",
        "              status[t] = \"PLAYER\"\n",
        "              break\n",
        "for title in tqdm(df[\"title\"]):\n",
        "  doc = nlp(title.lower())\n",
        "  for t in doc.ents:\n",
        "    if t.label_ in [\"ORG\" , \"GPE\" , \"PERSON\"]:\n",
        "      match = re.search(r\"(([a-z]+.?)+)\",t.text)\n",
        "      if match != None:\n",
        "        t = strip_accents(match.group())\n",
        "        if t not in status: \n",
        "          for team in teams:  \n",
        "            if t in strip_accents(team[0].lower()):\n",
        "              status[t] = \"TEAM\"\n",
        "              break\n",
        "        if t not in status:\n",
        "          for player in players:\n",
        "            if t in strip_accents(player[0].lower()):\n",
        "              status[t] = \"PLAYER\"\n",
        "              break"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12580/12580 [51:07<00:00,  4.10it/s]\n",
            "100%|██████████| 12580/12580 [04:18<00:00, 48.67it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ_nDMvK2s2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getLabel(x):\n",
        "  x = strip_accents(x.lower())\n",
        "  if x in status:\n",
        "    return status[x]\n",
        "  else:\n",
        "    return \"None\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YugAvBw-9PX-",
        "colab_type": "code",
        "outputId": "e0a70196-f130-48be-bc54-d8e7bf1fc3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "'''\n",
        "  TRAIN_DATA = [\n",
        "      (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
        "      (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOC\"), (18, 24, \"LOC\")]}),\n",
        "  ]\n",
        "'''\n",
        "TRAINING_DATA = []\n",
        "for x in tqdm(df[\"title\"]):\n",
        "  sentence = x\n",
        "  doc = nlp(x)\n",
        "  entities = []\n",
        "  for token in doc.ents:\n",
        "    start = token.start_char-token.sent.start_char\n",
        "    end = token.end_char-token.sent.start_char\n",
        "    if token.label_  in [\"ORG\" , \"GPE\" , \"PERSON\",\"FAC\"]:\n",
        "      if getLabel(token.text) == \"None\" :\n",
        "        label = token.label_\n",
        "      else:\n",
        "        label = getLabel(token.text)\n",
        "    else:\n",
        "      label = token.label_\n",
        "    entities.append((start ,end, label))\n",
        "  TRAINING_DATA.append((sentence,{\"entities\" : entities}))\n",
        "len(TRAINING_DATA)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12580/12580 [02:05<00:00, 99.95it/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12580"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h45-0tXHYWW0",
        "colab_type": "code",
        "outputId": "d717e5d9-31a8-4df7-bf2e-3700c11cea78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"brown\")\n",
        "from nltk.corpus import brown\n",
        "for x in brown.fileids()[5:8]:\n",
        "  for y in brown.sents(x):\n",
        "    y = \" \".join(y)\n",
        "    sentence = y\n",
        "    doc = nlp(y)\n",
        "    entities = []\n",
        "    for token in doc.ents:\n",
        "      start = token.start_char-token.sent.start_char\n",
        "      end = token.end_char-token.sent.start_char\n",
        "      label = token.label_\n",
        "      entities.append((start ,end, label))\n",
        "    TRAINING_DATA.append((sentence,{\"entities\" : entities}))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0CjdR5KZGhK",
        "colab_type": "code",
        "outputId": "1f9ecb19-b6a7-46e2-c1fb-ed6d55d9b0c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "shuffle(TRAINING_DATA)\n",
        "len(TRAINING_DATA)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12900"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNkWXzWAowhL",
        "colab_type": "code",
        "outputId": "e9302d6a-b3e1-4c4f-c143-106023653dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "TRAINING_DATA[4]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('I will definitely be at Bayer Leverkusen next season - Havertz',\n",
              " {'entities': [(24, 40, 'ORG')]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FJH1o6lsFEs",
        "colab_type": "code",
        "outputId": "6f857f02-0de5-4e8a-e32b-5a3572a2ad6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def check_validity(td):\n",
        "  start = 0 \n",
        "  end = -1\n",
        "  for ent in td[1][\"entities\"]:\n",
        "    start = ent[0]\n",
        "    if start < end:\n",
        "      return(False)\n",
        "      break\n",
        "    end = ent[1] \n",
        "  return(True)\n",
        "TRAINING_DATA = [x for x in TRAINING_DATA if check_validity(x)]\n",
        "len(TRAINING_DATA)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aIrnTbAFZX6w",
        "colab": {}
      },
      "source": [
        "ner = nlp.get_pipe(\"ner\")\n",
        "ner.add_label(LABEL1)\n",
        "ner.add_label(LABEL2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3043955d-e539-40c9-caed-60162adeb3a4",
        "id": "JnXPA-6gZmLx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "move_names = list(ner.move_names)\n",
        "print(move_names)\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "other_pipes"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-ORG', 'B-DATE', 'B-PERSON', 'B-GPE', 'B-MONEY', 'B-CARDINAL', 'B-NORP', 'B-PERCENT', 'B-WORK_OF_ART', 'B-LOC', 'B-TIME', 'B-QUANTITY', 'B-FAC', 'B-EVENT', 'B-ORDINAL', 'B-PRODUCT', 'B-LAW', 'B-LANGUAGE', 'I-ORG', 'I-DATE', 'I-PERSON', 'I-GPE', 'I-MONEY', 'I-CARDINAL', 'I-NORP', 'I-PERCENT', 'I-WORK_OF_ART', 'I-LOC', 'I-TIME', 'I-QUANTITY', 'I-FAC', 'I-EVENT', 'I-ORDINAL', 'I-PRODUCT', 'I-LAW', 'I-LANGUAGE', 'L-ORG', 'L-DATE', 'L-PERSON', 'L-GPE', 'L-MONEY', 'L-CARDINAL', 'L-NORP', 'L-PERCENT', 'L-WORK_OF_ART', 'L-LOC', 'L-TIME', 'L-QUANTITY', 'L-FAC', 'L-EVENT', 'L-ORDINAL', 'L-PRODUCT', 'L-LAW', 'L-LANGUAGE', 'U-ORG', 'U-DATE', 'U-PERSON', 'U-GPE', 'U-MONEY', 'U-CARDINAL', 'U-NORP', 'U-PERCENT', 'U-WORK_OF_ART', 'U-LOC', 'U-TIME', 'U-QUANTITY', 'U-FAC', 'U-EVENT', 'U-ORDINAL', 'U-PRODUCT', 'U-LAW', 'U-LANGUAGE', 'O', 'B-TEAM', 'I-TEAM', 'L-TEAM', 'U-TEAM', 'B-PLAYER', 'I-PLAYER', 'L-PLAYER', 'U-PLAYER']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tagger', 'parser']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0ef4c67c-0901-4490-ed3c-8d11c42ef2c9",
        "id": "uH1e5hzXZqTG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from spacy.util import compounding , minibatch\n",
        "n_iter = 1\n",
        "optimizer = nlp.resume_training()\n",
        "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "  sizes = compounding(1.0, 4.0, 1.001)\n",
        "  last_loss = pd.DataFrame([{\"x\":0 , \"y\" : 100000}])\n",
        "  count = 0\n",
        "  for itn in tqdm(range(n_iter)):\n",
        "      shuffle(TRAINING_DATA)\n",
        "      batches = minibatch(TRAINING_DATA, size=sizes)\n",
        "      losses = {}\n",
        "      for batch in batches:\n",
        "          texts, annotations = zip(*batch)\n",
        "          nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
        "      clear_output(wait=True)\n",
        "      test_model()\n",
        "      print(\"Loss \", losses)\n",
        "      count = count + 1"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [02:47<00:00, 167.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TESTING MODEL\n",
            "\n",
            "\tDonovan 'a little worried' about Pulisic's £58m Chelsea move\n",
            "\t\tEntities [('Donovan', 'PLAYER'), ('Pulisic', 'NORP'), ('£58m', 'MONEY')]\n",
            "\n",
            "\tForza Roma! – Schick backtracks on Man Utd hint\n",
            "\t\tEntities [('Forza Roma', 'ORG'), ('Schick', 'PLAYER'), ('Man Utd', 'TEAM')]\n",
            "\n",
            "\tDimas, Nichols headline Wanderers departures\n",
            "\t\tEntities [('Dimas', 'PLAYER'), ('Nichols', 'PLAYER')]\n",
            "\n",
            "\tWenger regrets never signing Carrick for Arsenal\n",
            "\t\tEntities [('Wenger', 'ORG'), ('Carrick', 'TEAM'), ('Arsenal', 'TEAM')]\n",
            "\n",
            "\tWeah expecting to play as a No. 9 with Celtic\n",
            "\t\tEntities [('Weah', 'PLAYER'), ('9', 'CARDINAL'), ('Celtic', 'NORP')]\n",
            "\n",
            "Loss  {'ner': 80063.22681556157}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6795a398-15a5-4aba-9626-ede8b147eab6",
        "id": "-n8QP1qtZzYG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install pathlib\n",
        "from pathlib import Path\n",
        "new_model_name = \"en_fnew_md\"\n",
        "output_dir = \"./en_fnew_md\"\n",
        "output_dir = Path(output_dir)\n",
        "if not output_dir.exists():\n",
        "    output_dir.mkdir()\n",
        "nlp.meta[\"name\"] = new_model_name  # rename model\n",
        "nlp.to_disk(output_dir)\n",
        "print(\"Saved model to\", output_dir)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Saved model to en_fnew_md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tGtXyDzGZ2xc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "3a5e94fc-7748-404d-db3b-8724b88f5f01"
      },
      "source": [
        "!zip -r /content/gdrive/My\\ Drive/project\\ stuff/fmodel.zip en_fnew_md"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: en_fnew_md/ (stored 0%)\n",
            "updating: en_fnew_md/parser/ (stored 0%)\n",
            "updating: en_fnew_md/parser/model (deflated 7%)\n",
            "updating: en_fnew_md/parser/moves (deflated 56%)\n",
            "updating: en_fnew_md/parser/cfg (deflated 49%)\n",
            "updating: en_fnew_md/meta.json (deflated 46%)\n",
            "updating: en_fnew_md/tagger/ (stored 0%)\n",
            "updating: en_fnew_md/tagger/model (deflated 7%)\n",
            "updating: en_fnew_md/tagger/cfg (deflated 34%)\n",
            "updating: en_fnew_md/tagger/tag_map (deflated 50%)\n",
            "updating: en_fnew_md/ner/ (stored 0%)\n",
            "updating: en_fnew_md/ner/model (deflated 9%)\n",
            "updating: en_fnew_md/ner/moves (deflated 78%)\n",
            "updating: en_fnew_md/ner/cfg (deflated 49%)\n",
            "updating: en_fnew_md/tokenizer (deflated 79%)\n",
            "updating: en_fnew_md/vocab/ (stored 0%)\n",
            "updating: en_fnew_md/vocab/key2row (deflated 78%)\n",
            "updating: en_fnew_md/vocab/strings.json (deflated 61%)\n",
            "updating: en_fnew_md/vocab/lookups.bin (deflated 45%)\n",
            "updating: en_fnew_md/vocab/vectors (deflated 9%)\n",
            "updating: en_fnew_md/vocab/lexemes.bin (deflated 64%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkZ0kArtY1GU",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning Report data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0PdiAgA5iiOx",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukoDzeOHYnaS",
        "colab_type": "code",
        "outputId": "2c5fa87f-3508-447a-8a29-506794ba6529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!unzip /content/gdrive/My\\ Drive/project\\ stuff/fmodel.zip "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/project stuff/fmodel.zip\n",
            "replace en_fnew_md/parser/model? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EdcbYE2W062",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_fnew_md\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4AvV7dHx_em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/gdrive/My Drive/project stuff/transfer_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr59Uh2uz8E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleantext(text):\n",
        "  text=text.replace(\"\\n\",\" \")\n",
        "  text=text.replace(\"Other English editions\",\"\")\n",
        "  text=text[:-193]\n",
        "  text.strip()\n",
        "  return(text)\n",
        "df[\"content\"] = df[\"content\"].apply(cleantext);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwUPzXd20ltP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def datefix(x):\n",
        "  match = re.search(r\"\\d+/\\d+/\\d+\",x)\n",
        "  if match == None:\n",
        "    print(x)\n",
        "  else:\n",
        "    return(str(match.group()))\n",
        "df[\"date\"] = df[\"date\"].apply(datefix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVS23DDaz7Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkemph(x):\n",
        "  doc = nlp(x.lower())\n",
        "  for token in doc.ents:\n",
        "    if token.label_ == \"PERSON\":\n",
        "      return False\n",
        "  return True\n",
        "filtered_df = df[df[\"emphasis\"].apply(checkemph)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up7iKjaq2RqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = filtered_df\n",
        "del filtered_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWfirXBk_UKv",
        "colab_type": "code",
        "outputId": "8a22c3bf-3212-4060-e6a4-a54711e36137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['content', 'date', 'emphasis', 'subscript', 'subtitle', 'title',\n",
              "       'topic', 'url'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQrmLdWEBSOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEQQX9n6WOnL",
        "colab_type": "code",
        "outputId": "89241031-f400-4f64-f027-d71aff573b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "pattern = [{\"lemma\" : \"sign\"}]\n",
        "matcher.add(\"Sign\" , None , pattern)\n",
        "\n",
        "for title in df[\"title\"][0:10]:\n",
        "  doc = nlp(title)\n",
        "  matches = matcher(doc)\n",
        "  for match_id, start, end in matches:\n",
        "      matched_span = doc[start:end]\n",
        "      print(title)\n",
        "      print(matched_span.text)\n",
        "      print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How special video helped Dortmund beat Man Utd to Haaland as Raiola confirmed signing on Christmas Eve\n",
            "signing\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjVDb95JqV5D",
        "colab_type": "code",
        "outputId": "f1032b69-9222-4575-bca7-6019de914fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "for title in df[\"title\"][123:124]:\n",
        "  doc = nlp(title)\n",
        "  displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"562189345f9b4813862af23bc6621840-0\" class=\"displacy\" width=\"1220\" height=\"362.0\" direction=\"ltr\" style=\"max-width: none; height: 362.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Nketiah</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">not</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">ruling</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">out</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">loan</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">move</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">despite</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">Arsenal</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">trying</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">close</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">exit</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">door</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-0\" stroke-width=\"2px\" d=\"M70,227.0 C70,137.0 215.0,137.0 215.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,229.0 L62,217.0 78,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-1\" stroke-width=\"2px\" d=\"M160,227.0 C160,182.0 210.0,182.0 210.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M160,229.0 L152,217.0 168,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-2\" stroke-width=\"2px\" d=\"M250,227.0 C250,182.0 300.0,182.0 300.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prt</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M300.0,229.0 L308.0,217.0 292.0,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-3\" stroke-width=\"2px\" d=\"M430,227.0 C430,182.0 480.0,182.0 480.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M430,229.0 L422,217.0 438,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-4\" stroke-width=\"2px\" d=\"M250,227.0 C250,92.0 490.0,92.0 490.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M490.0,229.0 L498.0,217.0 482.0,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-5\" stroke-width=\"2px\" d=\"M250,227.0 C250,47.0 585.0,47.0 585.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M585.0,229.0 L593.0,217.0 577.0,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-6\" stroke-width=\"2px\" d=\"M610,227.0 C610,182.0 660.0,182.0 660.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M660.0,229.0 L668.0,217.0 652.0,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-7\" stroke-width=\"2px\" d=\"M250,227.0 C250,2.0 770.0,2.0 770.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770.0,229.0 L778.0,217.0 762.0,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-8\" stroke-width=\"2px\" d=\"M880,227.0 C880,182.0 930.0,182.0 930.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M880,229.0 L872,217.0 888,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-9\" stroke-width=\"2px\" d=\"M790,227.0 C790,137.0 935.0,137.0 935.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M935.0,229.0 L943.0,217.0 927.0,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-10\" stroke-width=\"2px\" d=\"M1060,227.0 C1060,182.0 1110.0,182.0 1110.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1060,229.0 L1052,217.0 1068,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-562189345f9b4813862af23bc6621840-0-11\" stroke-width=\"2px\" d=\"M970,227.0 C970,137.0 1115.0,137.0 1115.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-562189345f9b4813862af23bc6621840-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1115.0,229.0 L1123.0,217.0 1107.0,217.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAf_hvPaq9a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc1 = nlp(df[\"content\"][0])\n",
        "sum = 0.0\n",
        "for c in df[\"content\"][1:]:\n",
        "  doc = nlp(c)\n",
        "  sum = sum + doc.similarity(doc2)\n",
        "  doc1 = doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuPlqyCT2Syw",
        "colab_type": "code",
        "outputId": "69fd1fdf-1de3-4097-f375-8dc956c71d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "doc = nlp(df[\"title\"][1])\n",
        "for ent in doc.ents:\n",
        "  print(ent.text , ent.label_)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tello PLAYER\n",
            "Real Betis TEAM\n",
            "Barcelona TEAM\n",
            "€5m MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPEkKIn05ujf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}